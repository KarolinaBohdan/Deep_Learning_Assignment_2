{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32d72134",
   "metadata": {},
   "source": [
    "# Green Patent Detection (PatentSBERTa): Active Learning + LLM→Human HITL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318155aa",
   "metadata": {},
   "source": [
    "### Part A: Baseline Model (Frozen Embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "346ca52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing and importing all necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99feb5f9",
   "metadata": {},
   "source": [
    "1) Loading the 50k parquet and check columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d00edbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 1372910/1372910 [01:13<00:00, 18727.71 examples/s]\n",
      "Generating test split: 100%|██████████| 119384/119384 [00:06<00:00, 18309.65 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'date', 'text', 'A01B', 'A01C', 'A01D', 'A01F', 'A01G', 'A01H', 'A01J', 'A01K', 'A01L', 'A01M', 'A01N', 'A21B', 'A21C', 'A21D', 'A22B', 'A22C', 'A23B', 'A23C', 'A23D', 'A23F', 'A23G', 'A23J', 'A23K', 'A23L', 'A23N', 'A23P', 'A23V', 'A23Y', 'A24B', 'A24C', 'A24D', 'A24F', 'A41B', 'A41C', 'A41D', 'A41F', 'A41G', 'A41H', 'A42B', 'A42C', 'A43B', 'A43C', 'A43D', 'A44B', 'A44C', 'A44D', 'A45B', 'A45C', 'A45D', 'A45F', 'A46B', 'A46D', 'A47B', 'A47C', 'A47D', 'A47F', 'A47G', 'A47H', 'A47J', 'A47K', 'A47L', 'A61B', 'A61C', 'A61D', 'A61F', 'A61G', 'A61H', 'A61J', 'A61K', 'A61L', 'A61M', 'A61N', 'A61P', 'A61Q', 'A62B', 'A62C', 'A62D', 'A63B', 'A63C', 'A63D', 'A63F', 'A63G', 'A63H', 'A63J', 'A63K', 'B01B', 'B01D', 'B01F', 'B01J', 'B01L', 'B02B', 'B02C', 'B03B', 'B03C', 'B03D', 'B04B', 'B04C', 'B05B', 'B05C', 'B05D', 'B06B', 'B07B', 'B07C', 'B08B', 'B09B', 'B09C', 'B21B', 'B21C', 'B21D', 'B21F', 'B21G', 'B21H', 'B21J', 'B21K', 'B21L', 'B22C', 'B22D', 'B22F', 'B23B', 'B23C', 'B23D', 'B23F', 'B23G', 'B23H', 'B23K', 'B23P', 'B23Q', 'B24B', 'B24C', 'B24D', 'B25B', 'B25C', 'B25D', 'B25F', 'B25G', 'B25H', 'B25J', 'B26B', 'B26D', 'B26F', 'B27B', 'B27C', 'B27D', 'B27F', 'B27G', 'B27H', 'B27J', 'B27K', 'B27L', 'B27M', 'B27N', 'B28B', 'B28C', 'B28D', 'B29B', 'B29C', 'B29D', 'B29K', 'B29L', 'B30B', 'B31B', 'B31C', 'B31D', 'B31F', 'B32B', 'B33Y', 'B41B', 'B41C', 'B41D', 'B41F', 'B41G', 'B41J', 'B41K', 'B41L', 'B41M', 'B41N', 'B41P', 'B42B', 'B42C', 'B42D', 'B42F', 'B42P', 'B43K', 'B43L', 'B43M', 'B44B', 'B44C', 'B44D', 'B44F', 'B60B', 'B60C', 'B60D', 'B60F', 'B60G', 'B60H', 'B60J', 'B60K', 'B60L', 'B60M', 'B60N', 'B60P', 'B60Q', 'B60R', 'B60S', 'B60T', 'B60V', 'B60W', 'B60Y', 'B61B', 'B61C', 'B61D', 'B61F', 'B61G', 'B61H', 'B61J', 'B61K', 'B61L', 'B62B', 'B62C', 'B62D', 'B62H', 'B62J', 'B62K', 'B62L', 'B62M', 'B63B', 'B63C', 'B63G', 'B63H', 'B63J', 'B64B', 'B64C', 'B64D', 'B64F', 'B64G', 'B65B', 'B65C', 'B65D', 'B65F', 'B65G', 'B65H', 'B66B', 'B66C', 'B66D', 'B66F', 'B67B', 'B67C', 'B67D', 'B68B', 'B68C', 'B68F', 'B68G', 'B81B', 'B81C', 'B82B', 'B82Y', 'C01B', 'C01C', 'C01D', 'C01F', 'C01G', 'C01P', 'C02F', 'C03B', 'C03C', 'C04B', 'C05B', 'C05C', 'C05D', 'C05F', 'C05G', 'C06B', 'C06C', 'C06D', 'C07B', 'C07C', 'C07D', 'C07F', 'C07G', 'C07H', 'C07J', 'C07K', 'C08B', 'C08C', 'C08F', 'C08G', 'C08H', 'C08J', 'C08K', 'C08L', 'C09B', 'C09C', 'C09D', 'C09F', 'C09G', 'C09H', 'C09J', 'C09K', 'C10B', 'C10C', 'C10F', 'C10G', 'C10H', 'C10J', 'C10K', 'C10L', 'C10M', 'C10N', 'C11B', 'C11C', 'C11D', 'C12C', 'C12F', 'C12G', 'C12H', 'C12J', 'C12L', 'C12M', 'C12N', 'C12P', 'C12Q', 'C12R', 'C12Y', 'C13B', 'C13K', 'C14B', 'C14C', 'C21B', 'C21C', 'C21D', 'C22B', 'C22C', 'C22F', 'C23C', 'C23D', 'C23F', 'C23G', 'C25B', 'C25C', 'C25D', 'C25F', 'C30B', 'C40B', 'D01B', 'D01C', 'D01D', 'D01F', 'D01G', 'D01H', 'D02G', 'D02H', 'D02J', 'D03C', 'D03D', 'D03J', 'D04B', 'D04C', 'D04D', 'D04G', 'D04H', 'D05B', 'D05C', 'D05D', 'D06B', 'D06C', 'D06F', 'D06G', 'D06H', 'D06J', 'D06L', 'D06M', 'D06N', 'D06P', 'D06Q', 'D07B', 'D10B', 'D21B', 'D21C', 'D21D', 'D21F', 'D21G', 'D21H', 'D21J', 'E01B', 'E01C', 'E01D', 'E01F', 'E01H', 'E02B', 'E02C', 'E02D', 'E02F', 'E03B', 'E03C', 'E03D', 'E03F', 'E04B', 'E04C', 'E04D', 'E04F', 'E04G', 'E04H', 'E05B', 'E05C', 'E05D', 'E05F', 'E05G', 'E05Y', 'E06B', 'E06C', 'E21B', 'E21C', 'E21D', 'E21F', 'F01B', 'F01C', 'F01D', 'F01K', 'F01L', 'F01M', 'F01N', 'F01P', 'F02B', 'F02C', 'F02D', 'F02F', 'F02G', 'F02K', 'F02M', 'F02N', 'F02P', 'F03B', 'F03C', 'F03D', 'F03G', 'F03H', 'F04B', 'F04C', 'F04D', 'F04F', 'F05B', 'F05C', 'F05D', 'F15B', 'F15C', 'F15D', 'F16B', 'F16C', 'F16D', 'F16F', 'F16G', 'F16H', 'F16J', 'F16K', 'F16L', 'F16M', 'F16N', 'F16P', 'F16S', 'F16T', 'F17B', 'F17C', 'F17D', 'F21H', 'F21K', 'F21L', 'F21S', 'F21V', 'F21W', 'F21Y', 'F22B', 'F22D', 'F22G', 'F23B', 'F23C', 'F23D', 'F23G', 'F23H', 'F23J', 'F23K', 'F23L', 'F23M', 'F23N', 'F23Q', 'F23R', 'F24B', 'F24C', 'F24D', 'F24F', 'F24H', 'F24J', 'F24S', 'F24T', 'F24V', 'F25B', 'F25C', 'F25D', 'F25J', 'F26B', 'F27B', 'F27D', 'F27M', 'F28B', 'F28C', 'F28D', 'F28F', 'F28G', 'F41A', 'F41B', 'F41C', 'F41F', 'F41G', 'F41H', 'F41J', 'F42B', 'F42C', 'F42D', 'G01B', 'G01C', 'G01D', 'G01F', 'G01G', 'G01H', 'G01J', 'G01K', 'G01L', 'G01M', 'G01N', 'G01P', 'G01Q', 'G01R', 'G01S', 'G01T', 'G01V', 'G01W', 'G02B', 'G02C', 'G02F', 'G03B', 'G03C', 'G03D', 'G03F', 'G03G', 'G03H', 'G04B', 'G04C', 'G04D', 'G04F', 'G04G', 'G04R', 'G05B', 'G05D', 'G05F', 'G05G', 'G06C', 'G06D', 'G06E', 'G06F', 'G06G', 'G06J', 'G06K', 'G06M', 'G06N', 'G06Q', 'G06T', 'G07B', 'G07C', 'G07D', 'G07F', 'G07G', 'G08B', 'G08C', 'G08G', 'G09B', 'G09C', 'G09D', 'G09F', 'G09G', 'G10B', 'G10C', 'G10D', 'G10F', 'G10G', 'G10H', 'G10K', 'G10L', 'G11B', 'G11C', 'G12B', 'G16B', 'G16C', 'G16H', 'G16Z', 'G21B', 'G21C', 'G21D', 'G21F', 'G21G', 'G21H', 'G21J', 'G21K', 'G21Y', 'H01B', 'H01C', 'H01F', 'H01G', 'H01H', 'H01J', 'H01K', 'H01L', 'H01M', 'H01P', 'H01Q', 'H01R', 'H01S', 'H01T', 'H02B', 'H02G', 'H02H', 'H02J', 'H02K', 'H02M', 'H02N', 'H02P', 'H02S', 'H03B', 'H03C', 'H03D', 'H03F', 'H03G', 'H03H', 'H03J', 'H03K', 'H03L', 'H03M', 'H04B', 'H04H', 'H04J', 'H04K', 'H04L', 'H04M', 'H04N', 'H04Q', 'H04R', 'H04S', 'H04W', 'H05B', 'H05C', 'H05F', 'H05G', 'H05H', 'H05K', 'Y02A', 'Y02B', 'Y02C', 'Y02D', 'Y02E', 'Y02P', 'Y02T', 'Y02W', 'Y04S', 'Y10S', 'Y10T'],\n",
      "    num_rows: 1372910\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"AI-Growth-Lab/patents_claims_1.5m_traim_test\", split=\"train\")\n",
    "print(ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25c55d8",
   "metadata": {},
   "source": [
    "2. Load train+test and put into one pandas df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a56029fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1492294, 666)\n",
      "Index(['id', 'date', 'text', 'A01B', 'A01C', 'A01D', 'A01F', 'A01G', 'A01H',\n",
      "       'A01J', 'A01K', 'A01L', 'A01M', 'A01N', 'A21B', 'A21C', 'A21D', 'A22B',\n",
      "       'A22C', 'A23B'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>A01B</th>\n",
       "      <th>A01C</th>\n",
       "      <th>A01D</th>\n",
       "      <th>A01F</th>\n",
       "      <th>A01G</th>\n",
       "      <th>A01H</th>\n",
       "      <th>A01J</th>\n",
       "      <th>...</th>\n",
       "      <th>Y02B</th>\n",
       "      <th>Y02C</th>\n",
       "      <th>Y02D</th>\n",
       "      <th>Y02E</th>\n",
       "      <th>Y02P</th>\n",
       "      <th>Y02T</th>\n",
       "      <th>Y02W</th>\n",
       "      <th>Y04S</th>\n",
       "      <th>Y10S</th>\n",
       "      <th>Y10T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8788730</td>\n",
       "      <td>2014-07-22</td>\n",
       "      <td>1. A method for sending a keycode of a non-key...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8621421</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>1. A method executed at least in part in a com...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 666 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id        date                                               text  \\\n",
       "0  8788730  2014-07-22  1. A method for sending a keycode of a non-key...   \n",
       "1  8621421  2013-12-31  1. A method executed at least in part in a com...   \n",
       "\n",
       "   A01B  A01C  A01D  A01F  A01G  A01H  A01J  ...  Y02B  Y02C  Y02D  Y02E  \\\n",
       "0     0     0     0     0     0     0     0  ...     0     0     0     0   \n",
       "1     0     0     0     0     0     0     0  ...     0     0     0     0   \n",
       "\n",
       "   Y02P  Y02T  Y02W  Y04S  Y10S  Y10T  \n",
       "0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0  \n",
       "\n",
       "[2 rows x 666 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train = load_dataset(\"AI-Growth-Lab/patents_claims_1.5m_traim_test\", split=\"train\")\n",
    "ds_test  = load_dataset(\"AI-Growth-Lab/patents_claims_1.5m_traim_test\", split=\"test\")\n",
    "\n",
    "df = pd.concat([ds_train.to_pandas(), ds_test.to_pandas()], ignore_index=True)\n",
    "\n",
    "print(df.shape)\n",
    "print(df.columns[:20])\n",
    "df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e594d2e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>A01B</th>\n",
       "      <th>A01C</th>\n",
       "      <th>A01D</th>\n",
       "      <th>A01F</th>\n",
       "      <th>A01G</th>\n",
       "      <th>A01H</th>\n",
       "      <th>A01J</th>\n",
       "      <th>...</th>\n",
       "      <th>Y02B</th>\n",
       "      <th>Y02C</th>\n",
       "      <th>Y02D</th>\n",
       "      <th>Y02E</th>\n",
       "      <th>Y02P</th>\n",
       "      <th>Y02T</th>\n",
       "      <th>Y02W</th>\n",
       "      <th>Y04S</th>\n",
       "      <th>Y10S</th>\n",
       "      <th>Y10T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8788730</td>\n",
       "      <td>2014-07-22</td>\n",
       "      <td>1. A method for sending a keycode of a non-key...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8621421</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>1. A method executed at least in part in a com...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9461433</td>\n",
       "      <td>2016-10-04</td>\n",
       "      <td>1. A light-emitting device comprising: a base;...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9229528</td>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>1. An input apparatus, comprising: a plurality...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8508147</td>\n",
       "      <td>2013-08-13</td>\n",
       "      <td>1. A dimmer circuit, comprising: a bleeder as ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 666 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id        date                                               text  \\\n",
       "0  8788730  2014-07-22  1. A method for sending a keycode of a non-key...   \n",
       "1  8621421  2013-12-31  1. A method executed at least in part in a com...   \n",
       "2  9461433  2016-10-04  1. A light-emitting device comprising: a base;...   \n",
       "3  9229528  2016-01-05  1. An input apparatus, comprising: a plurality...   \n",
       "4  8508147  2013-08-13  1. A dimmer circuit, comprising: a bleeder as ...   \n",
       "\n",
       "   A01B  A01C  A01D  A01F  A01G  A01H  A01J  ...  Y02B  Y02C  Y02D  Y02E  \\\n",
       "0     0     0     0     0     0     0     0  ...     0     0     0     0   \n",
       "1     0     0     0     0     0     0     0  ...     0     0     0     0   \n",
       "2     0     0     0     0     0     0     0  ...     0     0     0     0   \n",
       "3     0     0     0     0     0     0     0  ...     0     0     0     0   \n",
       "4     0     0     0     0     0     0     0  ...     0     0     0     0   \n",
       "\n",
       "   Y02P  Y02T  Y02W  Y04S  Y10S  Y10T  \n",
       "0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0  \n",
       "2     0     0     0     0     0     0  \n",
       "3     0     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 666 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064990ef",
   "metadata": {},
   "source": [
    "3. Creating is_green_silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abf48aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y02 columns: ['Y02A', 'Y02B', 'Y02C', 'Y02D', 'Y02E', 'Y02P', 'Y02T', 'Y02W']  ... total: 8\n"
     ]
    }
   ],
   "source": [
    "#Finding any columns starting with Y02\n",
    "y02_cols = [c for c in df.columns if str(c).startswith(\"Y02\")]\n",
    "print(\"Y02 columns:\", y02_cols[:20], \" ... total:\", len(y02_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e0d9c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATING THE LABEL\n",
    "if len(y02_cols) > 0:\n",
    "    df[\"is_green_silver\"] = (df[y02_cols].sum(axis=1) > 0).astype(int)\n",
    "else:\n",
    "    raise ValueError(\"No Y02* columns found. We need to inspect how green tech is encoded in this dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d1283ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_green_silver\n",
      "0    1379456\n",
      "1     112838\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Checking balance\n",
    "print(df[\"is_green_silver\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5e84de",
   "metadata": {},
   "source": [
    "4. Creating the balanced 50k sample (25k green + 25k not green)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3660756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_green_silver\n",
       "0    25000\n",
       "1    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 42\n",
    "\n",
    "green = df[df[\"is_green_silver\"] == 1].sample(25000, random_state=SEED)\n",
    "nong  = df[df[\"is_green_silver\"] == 0].sample(25000, random_state=SEED)\n",
    "\n",
    "balanced = pd.concat([green, nong], ignore_index=True).sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "\n",
    "balanced[\"is_green_silver\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfe6a34",
   "metadata": {},
   "source": [
    "5. Creating splits and save patents_50k_green.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cef9a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split\n",
       "train_silver      35000\n",
       "pool_unlabeled     7500\n",
       "eval_silver        7500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = balanced.sample(frac=0.70, random_state=SEED)\n",
    "rest = balanced.drop(train.index)\n",
    "\n",
    "eval_ = rest.sample(frac=0.50, random_state=SEED)   # half of remaining = 15%\n",
    "pool  = rest.drop(eval_.index)                      # remaining = 15%\n",
    "\n",
    "train = train.copy(); eval_ = eval_.copy(); pool = pool.copy()\n",
    "train[\"split\"] = \"train_silver\"\n",
    "eval_[\"split\"]  = \"eval_silver\"\n",
    "pool[\"split\"]   = \"pool_unlabeled\"\n",
    "\n",
    "final_df = pd.concat([train, pool, eval_], ignore_index=True)\n",
    "\n",
    "final_df.to_parquet(\"patents_50k_green.parquet\", index=False)\n",
    "final_df[\"split\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8f0a56a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloaded working dataset: (50000, 668)\n"
     ]
    }
   ],
   "source": [
    "# From this point on, always load from the working dataset\n",
    "final_df = pd.read_parquet(\"patents_50k_green.parquet\")\n",
    "print(\"Reloaded working dataset:\", final_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9520668a",
   "metadata": {},
   "source": [
    "6. Computing frozen PatentSBERTa embeddings for train+eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95295b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1094/1094 [1:06:01<00:00,  3.62s/it]\n",
      "100%|██████████| 235/235 [12:07<00:00,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35000, 768) (7500, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "MODEL_NAME = \"AI-Growth-Lab/PatentSBERTa\"\n",
    "TEXT_COL = \"text\"\n",
    "LABEL_COL = \"is_green_silver\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "encoder = AutoModel.from_pretrained(MODEL_NAME)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder.to(device)\n",
    "encoder.eval()\n",
    "\n",
    "@torch.no_grad()\n",
    "def embed_texts(texts, batch_size=32, max_length=256):\n",
    "    vecs = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        enc = tokenizer(\n",
    "            batch,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "        \n",
    "        out = encoder(**enc).last_hidden_state  # (B,T,H)\n",
    "        mask = enc[\"attention_mask\"].unsqueeze(-1).float()\n",
    "        pooled = (out * mask).sum(1) / mask.sum(1).clamp(min=1e-9)  # mean pooling\n",
    "        \n",
    "        vecs.append(pooled.cpu().numpy())\n",
    "    return np.vstack(vecs)\n",
    "\n",
    "train_df = final_df[final_df[\"split\"] == \"train_silver\"].copy()\n",
    "eval_df  = final_df[final_df[\"split\"] == \"eval_silver\"].copy()\n",
    "\n",
    "X_train = embed_texts(train_df[TEXT_COL].astype(str).tolist())\n",
    "y_train = train_df[LABEL_COL].astype(int).values\n",
    "\n",
    "X_eval  = embed_texts(eval_df[TEXT_COL].astype(str).tolist())\n",
    "y_eval  = eval_df[LABEL_COL].astype(int).values\n",
    "\n",
    "print(X_train.shape, X_eval.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573e19e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved embeddings + labels ✅\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Saving\n",
    "np.save(\"X_train.npy\", X_train)\n",
    "np.save(\"y_train.npy\", y_train)\n",
    "np.save(\"X_eval.npy\", X_eval)\n",
    "np.save(\"y_eval.npy\", y_eval)\n",
    "\n",
    "print(\"Saved embeddings + labels ✅\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7a16e4",
   "metadata": {},
   "source": [
    "7. Training the baseline classifier with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2eac340",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable To disable this warning, you can either:\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable \t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "TOKENIZERS_PARALLELISMTo disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable =(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7788    0.7975    0.7881      3758\n",
      "           1     0.7916    0.7726    0.7820      3742\n",
      "\n",
      "    accuracy                         0.7851      7500\n",
      "   macro avg     0.7852    0.7850    0.7850      7500\n",
      "weighted avg     0.7852    0.7851    0.7850      7500\n",
      "\n",
      "Precision=0.7916  Recall=0.7726  F1=0.7820\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "\n",
    "clf = LogisticRegression(max_iter=2000, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "pred = clf.predict(X_eval)\n",
    "\n",
    "print(classification_report(y_eval, pred, digits=4))\n",
    "\n",
    "p, r, f1, _ = precision_recall_fscore_support(y_eval, pred, average=\"binary\")\n",
    "print(f\"Precision={p:.4f}  Recall={r:.4f}  F1={f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb31941",
   "metadata": {},
   "source": [
    "The baseline model using frozen PatentSBERTa embeddings and Logistic Regression achieved an F1-score of 0.782 on the evaluation set. The performance is significantly above random guessing but still imperfect, making it suitable for uncertainty sampling. The model produces meaningful probability estimates around the decision boundary (p ≈ 0.5), which are necessary to identify high-risk examples for human labeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28d19a4",
   "metadata": {},
   "source": [
    "### Part B: Identify High-Risk Examples (Uncertainty Sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4881d52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2ff4ac",
   "metadata": {},
   "source": [
    "1. Loading prepared 50k parquet (the one with splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "675ef507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split\n",
       "train_silver      35000\n",
       "pool_unlabeled     7500\n",
       "eval_silver        7500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "final_df = pd.read_parquet(\"patents_50k_green.parquet\")\n",
    "final_df[\"split\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecb0a16",
   "metadata": {},
   "source": [
    "2. Selecting pool_unlabeled (this is what we score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "824f3c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pool size: 7500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>A01B</th>\n",
       "      <th>A01C</th>\n",
       "      <th>A01D</th>\n",
       "      <th>A01F</th>\n",
       "      <th>A01G</th>\n",
       "      <th>A01H</th>\n",
       "      <th>A01J</th>\n",
       "      <th>...</th>\n",
       "      <th>Y02D</th>\n",
       "      <th>Y02E</th>\n",
       "      <th>Y02P</th>\n",
       "      <th>Y02T</th>\n",
       "      <th>Y02W</th>\n",
       "      <th>Y04S</th>\n",
       "      <th>Y10S</th>\n",
       "      <th>Y10T</th>\n",
       "      <th>is_green_silver</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35000</th>\n",
       "      <td>8879379</td>\n",
       "      <td>2014-11-04</td>\n",
       "      <td>1. A method to detect a phase connection of a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pool_unlabeled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35001</th>\n",
       "      <td>8398513</td>\n",
       "      <td>2013-03-19</td>\n",
       "      <td>1. A plate-link chain for a motor vehicle driv...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pool_unlabeled</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 668 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id        date                                               text  \\\n",
       "35000  8879379  2014-11-04  1. A method to detect a phase connection of a ...   \n",
       "35001  8398513  2013-03-19  1. A plate-link chain for a motor vehicle driv...   \n",
       "\n",
       "       A01B  A01C  A01D  A01F  A01G  A01H  A01J  ...  Y02D  Y02E  Y02P  Y02T  \\\n",
       "35000     0     0     0     0     0     0     0  ...     0     0     0     0   \n",
       "35001     0     0     0     0     0     0     0  ...     0     0     0     0   \n",
       "\n",
       "       Y02W  Y04S  Y10S  Y10T  is_green_silver           split  \n",
       "35000     0     0     0     0                0  pool_unlabeled  \n",
       "35001     0     0     0     0                0  pool_unlabeled  \n",
       "\n",
       "[2 rows x 668 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool_df = final_df[final_df[\"split\"] == \"pool_unlabeled\"].copy()\n",
    "print(\"Pool size:\", len(pool_df))\n",
    "pool_df.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9173a740",
   "metadata": {},
   "source": [
    "3. Creating embeddings for the pool (frozen PatentSBERTa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f8ccebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_COL = \"text\"          # patent text column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "26d097fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [16:56<00:00,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_pool: (7500, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_pool = embed_texts(\n",
    "    pool_df[TEXT_COL].astype(str).tolist(),\n",
    "    batch_size=48,\n",
    "    max_length=MAX_SEQ_LENGTH\n",
    ")\n",
    "print(\"X_pool:\", X_pool.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bacdcc",
   "metadata": {},
   "source": [
    "4. Computing p_green for each pool example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cbf199e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_green</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35000</th>\n",
       "      <td>0.688134</td>\n",
       "      <td>1. A method to detect a phase connection of a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35001</th>\n",
       "      <td>0.442564</td>\n",
       "      <td>1. A plate-link chain for a motor vehicle driv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35002</th>\n",
       "      <td>0.288172</td>\n",
       "      <td>1. A composition for removing or reducing micr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35003</th>\n",
       "      <td>0.530667</td>\n",
       "      <td>1. A monoclonal or polyclonal antibody selecte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35004</th>\n",
       "      <td>0.197066</td>\n",
       "      <td>1. A method in a mobile device for determining...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        p_green                                               text\n",
       "35000  0.688134  1. A method to detect a phase connection of a ...\n",
       "35001  0.442564  1. A plate-link chain for a motor vehicle driv...\n",
       "35002  0.288172  1. A composition for removing or reducing micr...\n",
       "35003  0.530667  1. A monoclonal or polyclonal antibody selecte...\n",
       "35004  0.197066  1. A method in a mobile device for determining..."
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool_df[\"p_green\"] = clf.predict_proba(X_pool)[:, 1]\n",
    "pool_df[[\"p_green\", TEXT_COL]].head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4634594",
   "metadata": {},
   "source": [
    "5. Computing uncertainty score u (formula: u=1−2⋅∣p−0.5∣)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5d778af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0022613876175343606 0.9998479878680508\n"
     ]
    }
   ],
   "source": [
    "pool_df[\"u\"] = 1 - 2 * np.abs(pool_df[\"p_green\"] - 0.5)\n",
    "\n",
    "# sanity check: u should be between 0 and 1\n",
    "print(pool_df[\"u\"].min(), pool_df[\"u\"].max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4cf34b",
   "metadata": {},
   "source": [
    "6. Selecting top 100 highest-u rows (most uncertain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d4f80608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_green</th>\n",
       "      <th>u</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41661</th>\n",
       "      <td>0.499996</td>\n",
       "      <td>0.999993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40522</th>\n",
       "      <td>0.500049</td>\n",
       "      <td>0.999902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36576</th>\n",
       "      <td>0.500073</td>\n",
       "      <td>0.999854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35842</th>\n",
       "      <td>0.499804</td>\n",
       "      <td>0.999609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38080</th>\n",
       "      <td>0.500281</td>\n",
       "      <td>0.999439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41968</th>\n",
       "      <td>0.499713</td>\n",
       "      <td>0.999426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38900</th>\n",
       "      <td>0.500313</td>\n",
       "      <td>0.999375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41232</th>\n",
       "      <td>0.500313</td>\n",
       "      <td>0.999375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41838</th>\n",
       "      <td>0.500322</td>\n",
       "      <td>0.999357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38933</th>\n",
       "      <td>0.500349</td>\n",
       "      <td>0.999302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        p_green         u\n",
       "41661  0.499996  0.999993\n",
       "40522  0.500049  0.999902\n",
       "36576  0.500073  0.999854\n",
       "35842  0.499804  0.999609\n",
       "38080  0.500281  0.999439\n",
       "41968  0.499713  0.999426\n",
       "38900  0.500313  0.999375\n",
       "41232  0.500313  0.999375\n",
       "41838  0.500322  0.999357\n",
       "38933  0.500349  0.999302"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hitl_df = pool_df.sort_values(\"u\", ascending=False).head(100).copy()\n",
    "hitl_df[[\"p_green\", \"u\"]].head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b88cc3",
   "metadata": {},
   "source": [
    "7. Adding the required empty HITL columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87330616",
   "metadata": {},
   "outputs": [],
   "source": [
    "hitl_df[\"llm_green_suggested\"] = \"\"\n",
    "hitl_df[\"llm_confidence\"] = \"\"\n",
    "hitl_df[\"llm_rationale\"] = \"\"\n",
    "hitl_df[\"is_green_human\"] = \"\"\n",
    "hitl_df[\"notes\"] = \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfdd778",
   "metadata": {},
   "source": [
    "8. Exporting hitl_green_100.csv with the required columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "302602eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ✅ hitl_green_100.csv\n"
     ]
    }
   ],
   "source": [
    "export_df = hitl_df.rename(columns={\"id\": \"doc_id\"})\n",
    "\n",
    "export_cols = [\n",
    "    \"doc_id\",\n",
    "    TEXT_COL,\n",
    "    \"p_green\",\n",
    "    \"u\",\n",
    "    \"llm_green_suggested\",\n",
    "    \"llm_confidence\",\n",
    "    \"llm_rationale\",\n",
    "    \"is_green_human\",\n",
    "    \"notes\"\n",
    "]\n",
    "\n",
    "export_df[export_cols].to_csv(\"hitl_green_100.csv\", index=False)\n",
    "print(\"Saved ✅ hitl_green_100.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d1db6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_green</th>\n",
       "      <th>u</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41661</th>\n",
       "      <td>0.499996</td>\n",
       "      <td>0.999993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40522</th>\n",
       "      <td>0.500049</td>\n",
       "      <td>0.999902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36576</th>\n",
       "      <td>0.500073</td>\n",
       "      <td>0.999854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35842</th>\n",
       "      <td>0.499804</td>\n",
       "      <td>0.999609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38080</th>\n",
       "      <td>0.500281</td>\n",
       "      <td>0.999439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41968</th>\n",
       "      <td>0.499713</td>\n",
       "      <td>0.999426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38900</th>\n",
       "      <td>0.500313</td>\n",
       "      <td>0.999375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41232</th>\n",
       "      <td>0.500313</td>\n",
       "      <td>0.999375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41838</th>\n",
       "      <td>0.500322</td>\n",
       "      <td>0.999357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38933</th>\n",
       "      <td>0.500349</td>\n",
       "      <td>0.999302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        p_green         u\n",
       "41661  0.499996  0.999993\n",
       "40522  0.500049  0.999902\n",
       "36576  0.500073  0.999854\n",
       "35842  0.499804  0.999609\n",
       "38080  0.500281  0.999439\n",
       "41968  0.499713  0.999426\n",
       "38900  0.500313  0.999375\n",
       "41232  0.500313  0.999375\n",
       "41838  0.500322  0.999357\n",
       "38933  0.500349  0.999302"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most uncertain should have p_green close to 0.5\n",
    "export_df[[\"p_green\", \"u\"]].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8cb0dd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline model saved ✅\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(clf, \"baseline_logreg.pkl\")\n",
    "print(\"Baseline model saved ✅\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0a71e2",
   "metadata": {},
   "source": [
    "### PART C: Implement LLM → Human HITL (Gold Labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098f1d6f",
   "metadata": {},
   "source": [
    "1. Loading hitl_green_100.csv and create a “labeling-only” file. This file will include ONLY doc_id and text + empty label columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4c0967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: hitl_green_100_label_only.csv ✅\n"
     ]
    }
   ],
   "source": [
    "hitl = pd.read_csv(\"hitl_green_100.csv\")\n",
    "\n",
    "# keep only claim text + required label columns (no p_green / u shown during labeling)\n",
    "label_df = hitl[[\"doc_id\", \"text\"]].copy()\n",
    "\n",
    "label_df[\"llm_green_suggested\"] = \"\"\n",
    "label_df[\"llm_confidence\"] = \"\"\n",
    "label_df[\"llm_rationale\"] = \"\"\n",
    "label_df[\"is_green_human\"] = \"\"   # to fill\n",
    "label_df[\"notes\"] = \"\"\n",
    "\n",
    "label_df.to_csv(\"hitl_green_100_label_only.csv\", index=False)\n",
    "print(\"Saved: hitl_green_100_label_only.csv ✅\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd35dfc",
   "metadata": {},
   "source": [
    "2. Auto labeling with Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc169849",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RETURN CODE: 0\n",
      "STDOUT: Thinking...\n",
      "Okay, the user wants me to reply only with a JSON object that has a key \"test\" and value 1. Let me make sure I understand the request correctly. They specified \"Reply ONLY with JSON: {\"test\": 1}\". So I need to output exactly that JSON without any additional text or explanations.\n",
      "\n",
      "First, \n",
      "STDERR: \u001b[?2026h\u001b[?25l\u001b[1G⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "prompt = \"Reply ONLY with JSON: {\\\"test\\\": 1}\"\n",
    "\n",
    "result = subprocess.run(\n",
    "    [\"ollama\", \"run\", \"qwen3:latest\"],\n",
    "    input=prompt,\n",
    "    capture_output=True,\n",
    "    text=True,\n",
    ")\n",
    "\n",
    "print(\"RETURN CODE:\", result.returncode)\n",
    "print(\"STDOUT:\", result.stdout[:300])\n",
    "print(\"STDERR:\", result.stderr[:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e8b41bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "requests.get(\"http://localhost:11434\").status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4783bfe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeling 1/100 doc_id=9349230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yb/q_r1rf793yd5sq9v1bwzxvpc0000gn/T/ipykernel_33979/564288202.py:72: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'high' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[i, \"llm_confidence\"] = out[\"llm_confidence\"]\n",
      "/var/folders/yb/q_r1rf793yd5sq9v1bwzxvpc0000gn/T/ipykernel_33979/564288202.py:73: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'The claim describes a system for implementing access control, which involves communication devices, databases, and message transmission. There is no mention of renewable energy, energy efficiency, emissions reduction, or any other green technology aspects. The focus is on access control and data transmission, which are general technological functions without an environmental purpose.' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[i, \"llm_rationale\"] = out[\"llm_rationale\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeling 2/100 doc_id=9098212\n",
      "Labeling 3/100 doc_id=8679883\n",
      "Labeling 4/100 doc_id=8928812\n",
      "Labeling 5/100 doc_id=8975620\n",
      "  (checkpoint saved)\n",
      "Labeling 6/100 doc_id=8555926\n",
      "Labeling 7/100 doc_id=8862535\n",
      "Labeling 8/100 doc_id=9809521\n",
      "Labeling 9/100 doc_id=8380927\n",
      "Labeling 10/100 doc_id=9216467\n",
      "  (checkpoint saved)\n",
      "Labeling 11/100 doc_id=8685428\n",
      "Labeling 12/100 doc_id=8944642\n",
      "Labeling 13/100 doc_id=9370096\n",
      "Labeling 14/100 doc_id=8788855\n",
      "Labeling 15/100 doc_id=8378336\n",
      "  (checkpoint saved)\n",
      "Labeling 16/100 doc_id=9324203\n",
      "Labeling 17/100 doc_id=9206114\n",
      "Labeling 18/100 doc_id=9536210\n",
      "Labeling 19/100 doc_id=8700276\n",
      "Labeling 20/100 doc_id=9325463\n",
      "  (checkpoint saved)\n",
      "Labeling 21/100 doc_id=9150447\n",
      "Labeling 22/100 doc_id=8895813\n",
      "Labeling 23/100 doc_id=9501132\n",
      "Labeling 24/100 doc_id=8936732\n",
      "Labeling 25/100 doc_id=9086874\n",
      "  (checkpoint saved)\n",
      "Labeling 26/100 doc_id=8791307\n",
      "Labeling 27/100 doc_id=8895142\n",
      "Labeling 28/100 doc_id=9551951\n",
      "Labeling 29/100 doc_id=8448150\n",
      "Labeling 30/100 doc_id=8490722\n",
      "  (checkpoint saved)\n",
      "Labeling 31/100 doc_id=8927615\n",
      "Labeling 32/100 doc_id=9598737\n",
      "Labeling 33/100 doc_id=8850356\n",
      "Labeling 34/100 doc_id=9312246\n",
      "Labeling 35/100 doc_id=8807173\n",
      "  (checkpoint saved)\n",
      "Labeling 36/100 doc_id=8476141\n",
      "Labeling 37/100 doc_id=8901666\n",
      "Labeling 38/100 doc_id=9845351\n",
      "Labeling 39/100 doc_id=9588923\n",
      "Labeling 40/100 doc_id=8588993\n",
      "  (checkpoint saved)\n",
      "Labeling 41/100 doc_id=9373307\n",
      "Labeling 42/100 doc_id=9677773\n",
      "Labeling 43/100 doc_id=9468609\n",
      "Labeling 44/100 doc_id=8656980\n",
      "Labeling 45/100 doc_id=8929092\n",
      "  (checkpoint saved)\n",
      "Labeling 46/100 doc_id=8754495\n",
      "Labeling 47/100 doc_id=8815323\n",
      "Labeling 48/100 doc_id=9381124\n",
      "Labeling 49/100 doc_id=8996703\n",
      "Labeling 50/100 doc_id=8860490\n",
      "  (checkpoint saved)\n",
      "Labeling 51/100 doc_id=8948831\n",
      "Labeling 52/100 doc_id=8741675\n",
      "Labeling 53/100 doc_id=9676379\n",
      "Labeling 54/100 doc_id=9698306\n",
      "Labeling 55/100 doc_id=9074296\n",
      "  (checkpoint saved)\n",
      "Labeling 56/100 doc_id=8417878\n",
      "Labeling 57/100 doc_id=9434796\n",
      "Labeling 58/100 doc_id=9514084\n",
      "Labeling 59/100 doc_id=8673733\n",
      "Labeling 60/100 doc_id=9012865\n",
      "  (checkpoint saved)\n",
      "Labeling 61/100 doc_id=9133611\n",
      "Labeling 62/100 doc_id=8669789\n",
      "Labeling 63/100 doc_id=8371871\n",
      "Labeling 64/100 doc_id=8431940\n",
      "Labeling 65/100 doc_id=9638427\n",
      "  (checkpoint saved)\n",
      "Labeling 66/100 doc_id=8722144\n",
      "Labeling 67/100 doc_id=9162759\n",
      "Labeling 68/100 doc_id=9153732\n",
      "Labeling 69/100 doc_id=8876467\n",
      "Labeling 70/100 doc_id=8439880\n",
      "  (checkpoint saved)\n",
      "Labeling 71/100 doc_id=8682262\n",
      "Labeling 72/100 doc_id=9750072\n",
      "Labeling 73/100 doc_id=8770850\n",
      "Labeling 74/100 doc_id=9309387\n",
      "Labeling 75/100 doc_id=9178412\n",
      "  (checkpoint saved)\n",
      "Labeling 76/100 doc_id=9738704\n",
      "Labeling 77/100 doc_id=9367066\n",
      "Labeling 78/100 doc_id=8956524\n",
      "Labeling 79/100 doc_id=9412302\n",
      "Labeling 80/100 doc_id=8883431\n",
      "  (checkpoint saved)\n",
      "Labeling 81/100 doc_id=8842443\n",
      "Labeling 82/100 doc_id=9206519\n",
      "Labeling 83/100 doc_id=8469122\n",
      "Labeling 84/100 doc_id=9282520\n",
      "Labeling 85/100 doc_id=9701338\n",
      "  (checkpoint saved)\n",
      "Labeling 86/100 doc_id=9171801\n",
      "Labeling 87/100 doc_id=8967537\n",
      "Labeling 88/100 doc_id=8868960\n",
      "Labeling 89/100 doc_id=8987563\n",
      "Labeling 90/100 doc_id=8537846\n",
      "  (checkpoint saved)\n",
      "Labeling 91/100 doc_id=9614178\n",
      "Labeling 92/100 doc_id=8481085\n",
      "Labeling 93/100 doc_id=8831913\n",
      "Labeling 94/100 doc_id=9822010\n",
      "Labeling 95/100 doc_id=9175315\n",
      "  (checkpoint saved)\n",
      "Labeling 96/100 doc_id=9427802\n",
      "Labeling 97/100 doc_id=8642793\n",
      "Labeling 98/100 doc_id=9011072\n",
      "Labeling 99/100 doc_id=8970930\n",
      "Labeling 100/100 doc_id=8504823\n",
      "  (checkpoint saved)\n",
      "Saved ✅ hitl_green_100_with_llm.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "INPUT_CSV = \"hitl_green_100_label_only.csv\"\n",
    "OUTPUT_CSV = \"hitl_green_100_with_llm.csv\"\n",
    "MODEL = \"qwen3:latest\"\n",
    "\n",
    "SYSTEM = \"\"\"You are labeling whether a patent CLAIM is GREEN technology.\n",
    "\n",
    "RULES:\n",
    "- Use ONLY the claim text provided. Do NOT use any metadata.\n",
    "- Output MUST be valid JSON only.\n",
    "- Fields:\n",
    "  - llm_green_suggested: 0 or 1\n",
    "  - llm_confidence: \"low\" or \"medium\" or \"high\"\n",
    "  - llm_rationale: 1-3 sentences and must quote short phrases from the claim text.\n",
    "\n",
    "Guidance:\n",
    "GREEN = renewable energy, energy efficiency, storage, emissions reduction, carbon capture, recycling, waste/water treatment, clean transport.\n",
    "NOT GREEN = general tech with no environmental purpose.\n",
    "\"\"\"\n",
    "\n",
    "def ollama_label(claim_text: str) -> dict:\n",
    "    payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"prompt\": SYSTEM + \"\\n\\nClaim:\\n\" + claim_text + \"\\n\\nReturn JSON now.\",\n",
    "        \"stream\": False,\n",
    "        \"format\": \"json\",          # <-- forces JSON\n",
    "        \"options\": {\n",
    "            \"temperature\": 0.0     # <-- reduces “creative” output\n",
    "        }\n",
    "    }\n",
    "    r = requests.post(\"http://localhost:11434/api/generate\", json=payload, timeout=180)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "\n",
    "    # With format=json, response is JSON text, usually in data[\"response\"]\n",
    "    # Example: {\"llm_green_suggested\":1,\"llm_confidence\":\"medium\",\"llm_rationale\":\"...\"}\n",
    "    import json\n",
    "    out = json.loads(data[\"response\"])\n",
    "\n",
    "    # Normalize + validate\n",
    "    out[\"llm_green_suggested\"] = int(out[\"llm_green_suggested\"])\n",
    "    out[\"llm_confidence\"] = str(out[\"llm_confidence\"]).strip().lower()\n",
    "    if out[\"llm_confidence\"] in (\"med\", \"mid\", \"moderate\"):\n",
    "        out[\"llm_confidence\"] = \"medium\"\n",
    "    assert out[\"llm_green_suggested\"] in (0, 1)\n",
    "    assert out[\"llm_confidence\"] in (\"low\", \"medium\", \"high\")\n",
    "    out[\"llm_rationale\"] = str(out[\"llm_rationale\"]).strip()\n",
    "    return out\n",
    "\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "\n",
    "# Ensure columns exist and start empty\n",
    "for col in [\"llm_green_suggested\",\"llm_confidence\",\"llm_rationale\",\"is_green_human\",\"notes\"]:\n",
    "    if col not in df.columns:\n",
    "        df[col] = np.nan\n",
    "\n",
    "df[\"llm_green_suggested\"] = np.nan\n",
    "df[\"llm_confidence\"] = np.nan\n",
    "df[\"llm_rationale\"] = np.nan\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    claim = str(row[\"text\"])\n",
    "    print(f\"Labeling {i+1}/{len(df)} doc_id={row['doc_id']}\")\n",
    "\n",
    "    try:\n",
    "        out = ollama_label(claim)\n",
    "        df.at[i, \"llm_green_suggested\"] = out[\"llm_green_suggested\"]\n",
    "        df.at[i, \"llm_confidence\"] = out[\"llm_confidence\"]\n",
    "        df.at[i, \"llm_rationale\"] = out[\"llm_rationale\"]\n",
    "    except Exception as e:\n",
    "        df.at[i, \"llm_rationale\"] = f\"ERROR: {e}\"\n",
    "        print(\"  ❌\", e)\n",
    "\n",
    "    if (i+1) % 5 == 0:\n",
    "        df.to_csv(OUTPUT_CSV, index=False)\n",
    "        print(\"  (checkpoint saved)\")\n",
    "\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"Saved ✅ {OUTPUT_CSV}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eb512409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actually filled rows: 100 out of 100\n",
      "0    0.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "5    0.0\n",
      "6    0.0\n",
      "7    0.0\n",
      "8    0.0\n",
      "9    0.0\n",
      "Name: llm_green_suggested, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"hitl_green_100_with_llm.csv\")\n",
    "\n",
    "filled = df[\"llm_green_suggested\"].notna().sum()\n",
    "print(\"Actually filled rows:\", filled, \"out of\", len(df))\n",
    "\n",
    "# show a few values to confirm\n",
    "print(df[\"llm_green_suggested\"].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a5c22a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 27 info:\n",
      "doc_id                                                           8895142\n",
      "text                   1. A carbon black having: a) a nitrogen BET su...\n",
      "llm_green_suggested                                                  1.0\n",
      "llm_confidence                                                      high\n",
      "llm_rationale          The claim mentions carbon black with a nitroge...\n",
      "is_green_human                                                       NaN\n",
      "notes                                                                NaN\n",
      "Name: 26, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# check info about row 27\n",
    "row_27 = df.iloc[26]\n",
    "print(\"Row 27 info:\")\n",
    "print(row_27)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbe9f95",
   "metadata": {},
   "source": [
    "Compute the override ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "83f22ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overrides: 6 out of 100\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "gold = pd.read_csv(\"hitl_green_100_gold.csv\", sep=\";\")\n",
    "\n",
    "gold[\"llm_green_suggested\"] = gold[\"llm_green_suggested\"].astype(int)\n",
    "gold[\"is_green_human\"] = gold[\"is_green_human\"].astype(int)\n",
    "\n",
    "gold[\"override\"] = gold[\"llm_green_suggested\"] != gold[\"is_green_human\"]\n",
    "\n",
    "print(\"Overrides:\", gold[\"override\"].sum(), \"out of\", len(gold))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c3d12a",
   "metadata": {},
   "source": [
    "### PART D: Final Model (Fine-Tune PatentSBERTa Once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e12a36ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 668)\n",
      "Index(['id', 'date', 'text', 'A01B', 'A01C', 'A01D', 'A01F', 'A01G', 'A01H',\n",
      "       'A01J',\n",
      "       ...\n",
      "       'Y02D', 'Y02E', 'Y02P', 'Y02T', 'Y02W', 'Y04S', 'Y10S', 'Y10T',\n",
      "       'is_green_silver', 'split'],\n",
      "      dtype='object', length=668)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "full_df = pd.read_parquet(\"patents_50k_green.parquet\")\n",
    "print(full_df.shape)\n",
    "print(full_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3ff447",
   "metadata": {},
   "source": [
    "1. Merging 100 human labels and create is_green_gold. Loading labeled HITL file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "eefce9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['doc_id', 'text', 'llm_green_suggested', 'llm_confidence',\n",
      "       'llm_rationale', 'is_green_human', 'notes'],\n",
      "      dtype='object')\n",
      "(100, 7)\n"
     ]
    }
   ],
   "source": [
    "hitl_gold = pd.read_csv(\"hitl_green_100_gold.csv\", sep=\";\")  \n",
    "print(hitl_gold.columns)\n",
    "print(hitl_gold.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a255a6c2",
   "metadata": {},
   "source": [
    "2. Creating gold label column in the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f8b69e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with human labels merged in: 100\n",
      "            id  is_green_silver  is_green_human  is_green_gold\n",
      "35124  8927615                1             0.0              0\n",
      "35211  8956524                1             0.0              0\n",
      "35323  9427802                0             0.0              0\n",
      "35415  8673733                0             0.0              0\n",
      "35459  8490722                1             0.0              0\n",
      "35508  9698306                0             0.0              0\n",
      "35547  9738704                1             0.0              0\n",
      "35742  9367066                1             0.0              0\n",
      "35757  8970930                0             0.0              0\n",
      "35796  9206114                1             0.0              0\n"
     ]
    }
   ],
   "source": [
    "# --- make sure the key column matches ---\n",
    "if \"doc_id\" in hitl_gold.columns and \"id\" not in hitl_gold.columns:\n",
    "    hitl_gold = hitl_gold.rename(columns={\"doc_id\": \"id\"})\n",
    "\n",
    "# keep only what we need\n",
    "hitl_gold_small = hitl_gold[[\"id\", \"is_green_human\"]].copy()\n",
    "\n",
    "# merge into the full dataset\n",
    "df = full_df.merge(hitl_gold_small, on=\"id\", how=\"left\")\n",
    "\n",
    "# create is_green_gold = silver everywhere, overwritten by human on the 100\n",
    "df[\"is_green_gold\"] = df[\"is_green_silver\"]\n",
    "mask = df[\"is_green_human\"].notna()\n",
    "df.loc[mask, \"is_green_gold\"] = df.loc[mask, \"is_green_human\"].astype(int)\n",
    "\n",
    "print(\"Rows with human labels merged in:\", mask.sum())\n",
    "print(df.loc[mask, [\"id\", \"is_green_silver\", \"is_green_human\", \"is_green_gold\"]].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0c5d98",
   "metadata": {},
   "source": [
    "3. Building train/eval + gold_100 sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "62014350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df: (35000, 670) label mean: 0.5004\n",
      "eval_df: (7500, 670) label mean: 0.49893333333333334\n",
      "gold_100_df: (100, 670) label mean: 0.05\n"
     ]
    }
   ],
   "source": [
    "# making sure labels are int\n",
    "df[\"is_green_gold\"] = df[\"is_green_gold\"].astype(int)\n",
    "\n",
    "# splits\n",
    "train_df = df[df[\"split\"] == \"train_silver\"].copy()\n",
    "eval_df  = df[df[\"split\"] == \"eval_silver\"].copy()\n",
    "\n",
    "# the 100 gold rows (where we have human label)\n",
    "gold_100_df = df[df[\"is_green_human\"].notna()].copy()\n",
    "\n",
    "print(\"train_df:\", train_df.shape, \"label mean:\", train_df[\"is_green_gold\"].mean())\n",
    "print(\"eval_df:\", eval_df.shape, \"label mean:\", eval_df[\"is_green_silver\"].mean())  # eval uses silver ground truth\n",
    "print(\"gold_100_df:\", gold_100_df.shape, \"label mean:\", gold_100_df[\"is_green_gold\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "82e35caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human greens: 5 out of 100\n",
      "Overrides vs silver: 46 out of 100\n"
     ]
    }
   ],
   "source": [
    "# how many human greens?\n",
    "print(\"Human greens:\", gold_100_df[\"is_green_gold\"].sum(), \"out of\", len(gold_100_df))\n",
    "\n",
    "# how many human overrides of SILVER?\n",
    "if \"is_green_silver\" in gold_100_df.columns:\n",
    "    overrides_silver = (gold_100_df[\"is_green_gold\"] != gold_100_df[\"is_green_silver\"]).sum()\n",
    "    print(\"Overrides vs silver:\", overrides_silver, \"out of\", len(gold_100_df))\n",
    "\n",
    "# how many human overrides of LLM (if you have llm column in that file)\n",
    "if \"llm_green_suggested\" in gold_100_df.columns:\n",
    "    overrides_llm = (gold_100_df[\"is_green_gold\"] != gold_100_df[\"llm_green_suggested\"]).sum()\n",
    "    print(\"Overrides vs LLM:\", overrides_llm, \"out of\", len(gold_100_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0bf7bb",
   "metadata": {},
   "source": [
    "4. Converting pandas dataframes to HuggingFace datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "49795f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 35000\n",
      "}) Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 7500\n",
      "}) Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 100\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "\n",
    "MODEL_NAME = \"AI-Growth-Lab/PatentSBERTa\"\n",
    "MAX_SEQ_LENGTH = 256\n",
    "\n",
    "# Train uses gold labels (this is the whole HITL idea)\n",
    "train_hf = Dataset.from_pandas(\n",
    "    train_df[[\"text\", \"is_green_gold\"]].rename(columns={\"is_green_gold\": \"label\"}),\n",
    "    preserve_index=False\n",
    ")\n",
    "\n",
    "# Eval must use SILVER labels (assignment requirement)\n",
    "eval_hf = Dataset.from_pandas(\n",
    "    eval_df[[\"text\", \"is_green_silver\"]].rename(columns={\"is_green_silver\": \"label\"}),\n",
    "    preserve_index=False\n",
    ")\n",
    "\n",
    "# Separate evaluation on human gold set\n",
    "gold_hf = Dataset.from_pandas(\n",
    "    gold_100_df[[\"text\", \"is_green_gold\"]].rename(columns={\"is_green_gold\": \"label\"}),\n",
    "    preserve_index=False\n",
    ")\n",
    "\n",
    "print(train_hf, eval_hf, gold_hf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93287f95",
   "metadata": {},
   "source": [
    "5. Tokeniing the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c126b7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 35000/35000 [00:08<00:00, 4139.06 examples/s]\n",
      "Map: 100%|██████████| 7500/7500 [00:01<00:00, 4668.81 examples/s]\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 4019.61 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize_fn(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=MAX_SEQ_LENGTH\n",
    "    )\n",
    "\n",
    "train_hf = train_hf.map(tokenize_fn, batched=True, remove_columns=[\"text\"])\n",
    "eval_hf  = eval_hf.map(tokenize_fn, batched=True, remove_columns=[\"text\"])\n",
    "gold_hf  = gold_hf.map(tokenize_fn, batched=True, remove_columns=[\"text\"])\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "print(\"Tokenization done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4429e69",
   "metadata": {},
   "source": [
    "6. Loading the classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5c36ac2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MPNetForSequenceClassification were not initialized from the model checkpoint at AI-Growth-Lab/PatentSBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e402d318",
   "metadata": {},
   "source": [
    "7. Training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b7e8d0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"patentsberta_green_ft\",\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    logging_steps=50,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    report_to=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a30cd9",
   "metadata": {},
   "source": [
    "8. Trainer + metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e9d316c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import Trainer\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    # Works across HF versions\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, average=\"binary\", zero_division=0\n",
    "    )\n",
    "    return {\"accuracy\": acc, \"precision\": p, \"recall\": r, \"f1\": f1}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_hf,\n",
    "    eval_dataset=eval_hf,          # this should be eval_silver\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2a2dd631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# small update"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
